{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqphd6UHg4_Z",
        "outputId": "ab983bf3-91d9-4405-fa88-d2e422fc2dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/dataset.zip\"  # Path to your ZIP file in Google Drive\n",
        "extract_to = \"/content/dataset\"  # Folder where you want to extract\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(\" Extraction complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OuKbo2mhJaD",
        "outputId": "ba659c5a-a9ff-4705-97ba-be4de7a8344a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, numpy as np\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "IMG_SIZE = 160\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "cat_path = '/content/dataset/dataset/cats'\n",
        "dog_path = '/content/dataset/dataset/dogs'\n",
        "\n",
        "def process_batch(folder, label):\n",
        "    features, labels = [], []\n",
        "    batch = []\n",
        "\n",
        "    for idx, file in enumerate(tqdm(os.listdir(folder))):\n",
        "        try:\n",
        "            img_path = os.path.join(folder, file)\n",
        "            img = load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "            img = img_to_array(img)\n",
        "            batch.append(img)\n",
        "\n",
        "            # Process batch\n",
        "            if len(batch) == BATCH_SIZE or idx == len(os.listdir(folder)) - 1:\n",
        "                batch_arr = preprocess_input(np.array(batch))\n",
        "                preds = model.predict(batch_arr, verbose=0)\n",
        "                features.extend(preds)\n",
        "                labels.extend([label]*len(preds))\n",
        "                batch = []  # Clear batch\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "cat_features, cat_labels = process_batch(cat_path, 0)\n",
        "dog_features, dog_labels = process_batch(dog_path, 1)\n",
        "\n",
        "X = np.array(cat_features + dog_features)\n",
        "y = np.array(cat_labels + dog_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "senoPjA0h5ja",
        "outputId": "60c0e81c-6b21-49b8-bb8f-32039caa512d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3448218581.py:10: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10026/10026 [01:37<00:00, 102.68it/s]\n",
            "100%|██████████| 10008/10008 [01:25<00:00, 117.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import pickle\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "model = SVC(kernel='linear', probability=True)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save\n",
        "with open(\"svm_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"✅ Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFXZe80yDyPi",
        "outputId": "3d194455-9acc-488f-bf9d-2fe590a98ee7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9600798403193613\n"
          ]
        }
      ]
    }
  ]
}